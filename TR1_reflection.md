#Feedback and Decisions
	
We got a lot of feedback in the first half of our review. The suggestions that most stood out to us are listed below; the order reflects how useful we find the suggestion (most useful on top).

* Analyze Tweets from people who follow our news sources.
* Compare Twitter sentiment analysis to actual public opinion polls.
* Use sentiment bar graphs to visualize the data (with a time slider to show how they fluctuate over time).
* Look at the public opinion polls runs by our news sources.
* Compare trending hashtags and the frequency at which articles related to that hashtag are being published.

We want to examine the possibility of incorporating each of these suggestions into our project, especially the first two. People who follow our news sources are more likely to be influenced by them, and it would be interesting to compare the polarities of the news sources, their followers on Twitter, and the general Twitter population. We should be able to easily refine our Tweets-search to collect Tweets from both the general Twitter population and followers of specific news sources -- in other words, it should be easy to incorporate that idea into our current plan.  

Also, while Twitter is one way to measure public opinion, another, possibly more comprehensive way to measure public opinion is actual public opinion polls. While they will undoubtedly be more limiting as far as topics and collecting data over time are concerned, they should be useful in seeing how legitimate Twitter is as a source of public opinion. Perhaps, our question should really be “Is there a causal relationship between the polarity of news sources and Twitter users towards different topics?” Again, it should be easy to incorporate this suggestion into our project -- it’s easy to collect data from public opinion polls, although the amount of data will be relatively small. 

Based on our discussion, we came up with a few new questions. 

* How to incorporate more topics into our analysis - people seem to be interested in more than what we are offering. Especially, it would be nice to incorporate feedback #1 and #2 to our project.
* How do we present our findings in a simple yet comprehensible formats?
* Is it worth having an interactive data? For example, a data set with time slider that shows the change of data over time - it will take long time to implement this feature, but is it worth the time and effort? Do people find it very useful and informative to have an interactive feature of the data analysis?

#Review Process Reflection

The review went well. We got a lot of help answering our first question (“How else can we analyze data to answer our question?”), but few answers to our second and third questions (“What other interesting questions can we answer with our current data analysis method and dataset?” and “How can we present our data in a compelling/interesting way?”). I think this was mostly because we were the last group and the reviews were running behind schedule (our review started at 4:50) so people wanted to leave. 

Since we weren’t getting as much participation after the first 10 minutes, we finished asking/getting answers to our key questions earlier than we had anticipated. Unfortunately for our audience, who were no doubt hungry and itching to leave, we decided to use the remaining time as an opportunity to ask people if they had ideas of cool things we could do with other available language analysis tools (political and subjectivity analysis). This sparked some interesting ideas, mostly unrelated to the question we were considering, but things we hadn’t considered before, like analyzing popular political figures’ statements to see if the language they use matches up with their purported political views. We’re planning to stick with our original question (“Is there a causal relationship between the polarity of news sources and public opinion towards different topics?”), but if that doesn’t pan out, the political analysis suggestion would be a good backup. 

Honestly, the biggest improvement we could make regarding our technical review is to not go last. It would also behoove us to have more specific questions and a more guided activity/discussion, although again, if we get a chance to present when people are more energetic, I think the discussion will be livelier regardless of any other changes we make. Thinking ahead of time during the presentation planning stage about what to do when audience is disengaged would be helpful too. It will also be easier to ask more specific questions when we get farther along in the project. 
